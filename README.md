# NLP_Assign

[用人话讲明白线性回归](https://zhuanlan.zhihu.com/p/72513104) <br>
[用人话讲明白梯度下降](https://zhuanlan.zhihu.com/p/137713040) <br>
[多项式朴素贝叶斯](https://zhuanlan.zhihu.com/p/386815121) <br>

一个写得不错的perceptron介绍：[人工智能知识全面讲解：感知机原理](http://t.csdnimg.cn/zXXFl)

NLP2 covers Chapt 6-11, possibly 12. <br>
Final Exam at 30th July. <br>

**Further Readings** <br>
Alammar, Jay. [The Illustrated Word2Vec](https://jalammar.github.io/illustrated-word2vec/)
Alammar, Jay. [The Illustrated Transformer](https://jalammar.github.io/illustratedtransformer/)
Alammar, Jay. [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq
Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translationmechanics-of-seq2seq-models-with-attention/)
Karpathy, Andrej. [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)



## Probability Theory

## N-Gram Models

## Text Classification & Naive Bayes

## Regression - Linear & Logistic

## Vector Semantics and Embeddings

## Neural Networks

## Tagging

## RNNs - Recurrent NNs

## The Transformer

## BERT


